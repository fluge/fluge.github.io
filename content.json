{"meta":{"title":"fluge site","subtitle":null,"description":"积累漫长而艰辛，coding....。","author":"fluge","url":"http://yoursite.com","root":"/"},"pages":[{"title":"","date":"2019-04-24T07:59:07.903Z","updated":"2019-04-24T06:43:51.998Z","comments":true,"path":"404.html","permalink":"http://yoursite.com/404.html","excerpt":"","text":"L2Dwidget.init({\"model\":{\"jsonPath\":\"/live2dw/assets/tororo.model.json\"},\"display\":{\"position\":\"right\",\"width\":150,\"height\":300},\"mobile\":{\"show\":false},\"log\":false,\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"pluginRootPath\":\"live2dw/\",\"tagMode\":false});"},{"title":"tags","date":"2016-11-28T09:36:00.000Z","updated":"2019-04-24T06:43:52.016Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"about","date":"2016-11-28T09:36:35.000Z","updated":"2019-04-24T10:36:02.722Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"目前在瓜子工作 常用语言golang，java 17年毕业，比较宅，喜欢LOL"},{"title":"search","date":"2016-11-28T09:36:35.000Z","updated":"2019-04-24T06:43:52.015Z","comments":true,"path":"search/index.html","permalink":"http://yoursite.com/search/index.html","excerpt":"","text":""},{"title":"categories","date":"2016-11-28T09:36:35.000Z","updated":"2019-04-24T06:43:52.013Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"IO模型 --- select,poll,epoll","slug":"IO模型 --- select,poll,epoll","date":"2019-05-16T03:20:55.000Z","updated":"2019-05-27T08:41:09.810Z","comments":true,"path":"2019/05/16/IO模型 --- select,poll,epoll/","link":"","permalink":"http://yoursite.com/2019/05/16/IO模型 --- select,poll,epoll/","excerpt":"最近在看网络编程模型，虽然Golang天然高并发的原因很大一部分是因为协程和channel,但是这个里面还是离不开底层的网络编程模型的选用 — epoll。在学习这部分的时候对IO多路复用做了一些了解。 一些概念内核空间和用户空间现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。 为了保证用户进程不能直接操作内核，保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。我们可以简单理解为，一张纸，四分之一给一个叫内核的人用，四分之三给一个叫用户的人用。 fd 文件操作描述符文件描述符在形式上是一个非负整数,它是一个索引值,指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。文件描述符这一概念往往只适用于Unix和Linux这样的操作系统。 缓存IO缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。就是从内核空间到用户空间需要经过两次复制操作。这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。","text":"最近在看网络编程模型，虽然Golang天然高并发的原因很大一部分是因为协程和channel,但是这个里面还是离不开底层的网络编程模型的选用 — epoll。在学习这部分的时候对IO多路复用做了一些了解。 一些概念内核空间和用户空间现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。 为了保证用户进程不能直接操作内核，保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。我们可以简单理解为，一张纸，四分之一给一个叫内核的人用，四分之三给一个叫用户的人用。 fd 文件操作描述符文件描述符在形式上是一个非负整数,它是一个索引值,指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。文件描述符这一概念往往只适用于Unix和Linux这样的操作系统。 缓存IO缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。就是从内核空间到用户空间需要经过两次复制操作。这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。 Linux的socket 事件wakeup callback机制Linux（2.6+）内核 会通过sleep_list等待队列，去管理所有正在等socket事件的process，会在sleep_list 中为当前正在等待的process构建一个wait_entry,只到超时或者事件触发，在每个wait_enrey上会定义一个callback同时wakeup机制会异步的唤醒整个sleep_list上的process，并同时执行callback ，删除sleep_list 上的wait_entry 节点。总体上会涉及两大逻辑： 睡眠机制 select、poll、epoll_wait陷入内核，判断监控的socket是否有关心的事件发生了，如果没，则为当前process构建一个wait_entry节点，然后插入到监控socket的sleep_list里取。 Linux调用schedule函数进行process的状态转换，shcedule函数是Linux的调度process的函数，这里指的是process进入sleep直到超时或者事件发生。 事件触发后，将当前process的wait_entry节点从socket的sleep_list中删除。 唤醒机制 socket的事件发生了，然后socket顺序遍历其睡眠队列sleep_list，依次调用每个wait_entry节点（对应各个Process）的callback函数。 直到完成队列的遍历或遇到某个wait_entry节点是排他的才停止。 一般情况下callback包含两个逻辑：wait_entry自定义的私有逻辑和唤醒的公共逻辑，主要用于将该wait_entry的process放入CPU的就绪队列，让CPU随后可以调度其执行。 IO模型对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段： 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) 正式因为这两个阶段，linux系统产生了下面五种网络模式的方案： 阻塞 I/O（blocking IO） 非阻塞 I/O（nonblocking IO） I/O 多路复用（ IO multiplexing） 信号驱动 I/O（ signal driven IO）(比较少用到) 异步 I/O（asynchronous IO） 阻塞 I/O（blocking IO）用户进程process在Blocking IO读recvfrom操作的两个阶段都是等待的。在数据没准备好的时候，process原地等待kernel准备数据。kernel准备好数据后，process继续等待kernel将数据copy到自己的buffer。在kernel完成数据的copy后process才会从recvfrom系统调用中返回。 非阻塞 I/O（NonBlocking IO）process在NonBlocking IO读recvfrom操作的第一个阶段是不会block等待的，如果kernel数据还没准备好，那么recvfrom会立刻返回一个EWOULDBLOCK错误。当kernel准备好数据后，进入处理的第二阶段的时候，process会等待kernel将数据copy到自己的buffer，在kernel完成数据的copy后process才会从recvfrom系统调用中返回。 IO多路复用（NonBlocking IO）IO多路复用，就是我们熟知的select、poll、epoll模型。从图上可见，在IO多路复用的时候，process在两个处理阶段都是block住等待的。初看好像IO多路复用没什么用，其实select、poll、epoll的优势在于·可以以较少的代价来同时监听处理多个IO。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"select","slug":"select","permalink":"http://yoursite.com/tags/select/"},{"name":"epoll","slug":"epoll","permalink":"http://yoursite.com/tags/epoll/"}]},{"title":"二叉树的几种遍历方式","slug":"二叉树的几种遍历方式","date":"2017-08-29T09:18:55.000Z","updated":"2019-05-07T15:06:16.665Z","comments":true,"path":"2017/08/29/二叉树的几种遍历方式/","link":"","permalink":"http://yoursite.com/2017/08/29/二叉树的几种遍历方式/","excerpt":"二叉树的各种遍历方式,包括递归和非递归的整理 前、中、后三种方式的递归和非递归 广度优先和层次遍历（树的深度的非递归解法） 深度优先前序遍历前序遍历就是：先根节点 —&gt; 左节点 —&gt; 右节点12345678910111213141516171819202122232425262728293031323334353637383940//递归解法func PreOrderTraversal(root *TreeNode) []int &#123; if root == nil &#123; return nil &#125; res := make([]int, 0) res = append(res, root.Val) if root.Left != nil &#123; res = append(res, PreOrderTraversal(root.Left)...) &#125; if root.Right != nil &#123; res = append(res, PreOrderTraversal(root.Right)...) &#125; return res&#125;//非递归解法func PreOrderTraversal2(root *TreeNode) []int &#123; if root == nil &#123; return nil &#125; stack := make([]*TreeNode, 0) res := make([]int, 0) //把根节点入栈 for root != nil || len(stack) &gt; 0 &#123; //不停的找做节点 for root != nil &#123; //根节点先输出 res = append(res, root.Val) stack = append(stack, root) root = root.Left &#125; //出栈操作 root = stack[len(stack)-1] stack = stack[:len(stack)-1] //遍历右节点 root = root.Right &#125; return res&#125;","text":"二叉树的各种遍历方式,包括递归和非递归的整理 前、中、后三种方式的递归和非递归 广度优先和层次遍历（树的深度的非递归解法） 深度优先前序遍历前序遍历就是：先根节点 —&gt; 左节点 —&gt; 右节点12345678910111213141516171819202122232425262728293031323334353637383940//递归解法func PreOrderTraversal(root *TreeNode) []int &#123; if root == nil &#123; return nil &#125; res := make([]int, 0) res = append(res, root.Val) if root.Left != nil &#123; res = append(res, PreOrderTraversal(root.Left)...) &#125; if root.Right != nil &#123; res = append(res, PreOrderTraversal(root.Right)...) &#125; return res&#125;//非递归解法func PreOrderTraversal2(root *TreeNode) []int &#123; if root == nil &#123; return nil &#125; stack := make([]*TreeNode, 0) res := make([]int, 0) //把根节点入栈 for root != nil || len(stack) &gt; 0 &#123; //不停的找做节点 for root != nil &#123; //根节点先输出 res = append(res, root.Val) stack = append(stack, root) root = root.Left &#125; //出栈操作 root = stack[len(stack)-1] stack = stack[:len(stack)-1] //遍历右节点 root = root.Right &#125; return res&#125; 中序遍历中序遍历就是：先左节点 —&gt; 根节点 —&gt; 右节点12345678910111213141516171819202122232425262728293031323334353637383940func InOrderTraversal(root *TreeNode) []int &#123; if root == nil &#123; return nil &#125; var ret []int lret := InOrderTraversal(root.Left) if len(lret) &gt; 0 &#123; ret = append(ret, lret...) &#125; ret = append(ret, root.Val) rret := InOrderTraversal(root.Right) if len(rret) &gt; 0 &#123; ret = append(ret, rret...) &#125; return ret&#125;//中序遍历的非递归 --- 使用栈func InOrderTraversal2(root *TreeNode) []int &#123; if root == nil &#123; return nil &#125; stack := make([]*TreeNode, 0) res := make([]int, 0) for root != nil || len(stack) &gt; 0 &#123; //把左子树一直入栈 for root != nil &#123; stack = append(stack, root) root = root.Left &#125; //对左子树出栈 root = stack[len(stack)-1] res = append(res, root.Val) stack = stack[:len(stack)-1] //有节点 root = root.Right &#125; return res&#125; 后序遍历后序遍历就是：先左节点 —&gt; 右节点 —&gt; 根节点12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//递归后序func PostOrderTraversal(root *TreeNode) []int &#123; if root == nil &#123; return nil &#125; res := make([]int, 0) if root.Left != nil &#123; res = append(res, PostOrderTraversal(root.Left)...) &#125; if root.Right != nil &#123; res = append(res, PostOrderTraversal(root.Right)...) &#125; res = append(res, root.Val) return res&#125;//非递归：使用双栈法func PostOrderTraversal2(root *TreeNode) []int &#123; if root == nil &#123; return nil &#125; //初始化一个栈 stack := make([]*TreeNode, 0) //根节点入栈 stack = append(stack, root) //结果集 res := make([]int, 0) for len(stack) &gt; 0 &#123; //取栈顶元素 node := stack[len(stack)-1] stack = stack[:len(stack)-1] if len(res) == 0 &#123; res = append(res, node.Val) &#125; else &#123; //向slice 的头插入对应的值（类似双栈里面的第二个栈） res = append(res[:1], res[0:]...) res[0] = node.Val &#125; if node.Left != nil &#123; stack = append(stack, node.Left) &#125; if node.Right != nil &#123; stack = append(stack, node.Right) &#125; &#125; return res&#125; 层次遍历层次遍历也可以叫做广度优先遍历，有几种解法，实现了其中的傀儡节点法123456789101112131415161718192021222324252627282930313233343536373839404142434445func LevelOrder(root *TreeNode) [][]int &#123; list := make([]*TreeNode, 0) res := make([][]int, 0) if root == nil &#123; return res &#125; //加入头节点 list = append(list, root) //加入傀儡节点（使用-1 作为傀儡节点） list = append(list, &amp;TreeNode&#123; Val: MinInt, &#125;) tmp := make([]int, 0) //表示不为空 for len(list) &gt; 0 &#123; if list[0].Val == MinInt &amp;&amp; list[0].Right == nil &amp;&amp; list[0].Left == nil &#123; //遍历到傀儡节点了，就在队列里面插入一个傀儡节点 list = append(list, &amp;TreeNode&#123; Val: MinInt, &#125;) if len(tmp) &gt; 0 &#123; res = append(res, tmp) //重新初始化一个tmp,表示另一层 tmp = make([]int, 0) &#125; else &#123; break &#125; &#125; else &#123; //不是傀儡节点，就把左右节点分别入队 tmp = append(tmp, list[0].Val) //有左右节点，先从做节点入队，然后是有节点 if list[0].Left != nil &#123; list = append(list, list[0].Left) &#125; if list[0].Right != nil &#123; list = append(list, list[0].Right) &#125; &#125; //把当前元素出队 list = list[1:] &#125; return res&#125; 类似求树的最大深度也可以用这个非递归的方式求解。 深度优先遍历深度优先就可以使用先序遍历来实现","categories":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/categories/算法/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"http://yoursite.com/tags/二叉树/"}]},{"title":"我理解的TCP协议(一)---链接的建立和终止","slug":"我理解的TCP协议(一)---链接的建立和终止","date":"2017-03-06T02:21:17.000Z","updated":"2019-05-16T08:47:42.607Z","comments":true,"path":"2017/03/06/我理解的TCP协议(一)---链接的建立和终止/","link":"","permalink":"http://yoursite.com/2017/03/06/我理解的TCP协议(一)---链接的建立和终止/","excerpt":"TCP是一个非常复杂的面向连接的协议,在很30多年来，各种优化变种争论和修改不断,所以我先从连接的建立和终止开始写TCP。后面应该还有几篇文章写TCP的另外几个特别重要的特性。TCP最开始被我知道就先从很有特点的链接建立和终止—三次握手和四次挥手,基本上TCP协议的可靠性就是从保证连接的可靠性开始的。 TCP链接的建立—三次握手对于三次握手，其实是TCP比较著名的东西了,在完全不了解这个TCP的时候就知道有这个东西了，但是开始的时候总有一点让我非常的疑惑:TCP为什么是三次握手,为什么不是两次或四次？ TCP 为什么是三次握手,为什么不是两次或四次？要解释这个问题,首先明白TCP出现的价值和思路:是为了在不可靠的互联网络上提供一个可靠的端到端字节流而设计的,并且一个TCP连接是全双工。这是TCP很重要的一个设计理念:提供了一种可靠的,面向连接的字节流运输层服务,并且是双全工的。这里需要理解双全工的意思：就是两端之间进行通信，这两端既可以是数据的接收方，也可以是数据的发送方。1、 可靠模型:但是为了数据的安全送达，就必须在发送数据前向另一个端口进行通信 数据发送端A:嘿,我想发送数据了,可以么。数据接收端B:好的，这边允许接受。 然后数据的发送端就可以发送数据了,这里就基本保证你发的在接收方会正常的接受并不会发错。这是发送数据的基本可靠模型。2、 连接模型:在TCP的要求中,需要一种面向连接的通信:连接在我理解中就是相当于有一根空水管,连接两个水池(为两个水池传输东西),在水管中传输东西的效率肯定会高于用桶去一桶桶的装,来的方便。","text":"TCP是一个非常复杂的面向连接的协议,在很30多年来，各种优化变种争论和修改不断,所以我先从连接的建立和终止开始写TCP。后面应该还有几篇文章写TCP的另外几个特别重要的特性。TCP最开始被我知道就先从很有特点的链接建立和终止—三次握手和四次挥手,基本上TCP协议的可靠性就是从保证连接的可靠性开始的。 TCP链接的建立—三次握手对于三次握手，其实是TCP比较著名的东西了,在完全不了解这个TCP的时候就知道有这个东西了，但是开始的时候总有一点让我非常的疑惑:TCP为什么是三次握手,为什么不是两次或四次？ TCP 为什么是三次握手,为什么不是两次或四次？要解释这个问题,首先明白TCP出现的价值和思路:是为了在不可靠的互联网络上提供一个可靠的端到端字节流而设计的,并且一个TCP连接是全双工。这是TCP很重要的一个设计理念:提供了一种可靠的,面向连接的字节流运输层服务,并且是双全工的。这里需要理解双全工的意思：就是两端之间进行通信，这两端既可以是数据的接收方，也可以是数据的发送方。1、 可靠模型:但是为了数据的安全送达，就必须在发送数据前向另一个端口进行通信 数据发送端A:嘿,我想发送数据了,可以么。数据接收端B:好的，这边允许接受。 然后数据的发送端就可以发送数据了,这里就基本保证你发的在接收方会正常的接受并不会发错。这是发送数据的基本可靠模型。2、 连接模型:在TCP的要求中,需要一种面向连接的通信:连接在我理解中就是相当于有一根空水管,连接两个水池(为两个水池传输东西),在水管中传输东西的效率肯定会高于用桶去一桶桶的装,来的方便。这两个模型联系起来:就是当两个水池之间要进行交换东西的时候,需要有一个水管去保持两边的交换的效率。这个时候就把水管的一边和一个水池相连(用水管的另一边进行可靠模型的验证)，如果验证通过在把另一边进行相连，然后再去用可靠模型验证。都通过就说明整个链接水管工作完成了。可以正常的工作。在上面的水管是虚拟的不存在的，抽象出整个可靠模型，然后简化整个过程:A,B连个端口 A:我想向你发送数据，可以么。B:可以啊。（第一次可靠验证结束）B:我想向你发送数据，可以么。A:可以啊。 (第二次可靠验证结束) 然后上面的过程其实可以进一步的优化就是把两次的可靠验证结合在一起:中间两次的B的发送数据显然可以合并为一次数据发送。上面就是我对为什么是三次握手,为什么不是两次或四次的理解的一个方向。两次握手只能让链接的一端发送的数据的是可信的，四次握手就显得有点多余。 TCP的三次握手具体过程TCP的三次握手除了要建立可靠的连接外还有就是初始化SYN(传输数据的包的序号)。也就下图中的x和y。这个号要作为以后的数据通信的序号，以保证应用层接收到的数据不会因为网络上的传输的问题而乱序（TCP会用这个序号来拼接数据）。基本过程: 第一次握手：客户端发送syn包(syn=x)到服务器，并进入SYN_SEND状态，等待服务器确认； 第二次握手：服务器收到syn包，必须确认客户的SYN（ack=x+1），同时自己也发送一个SYN包（syn=y），即SYN+ACK包，此时服务器进入SYN_RECV状态； 第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=y+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。 在握手中值得注意的细节是: 关于建连接时SYN超时。如果服务端接到了客户端发的SYN后回了ACK后client掉线了，服务器端没有收到客户端回来的ACK(第二次握手完成)，那么，这个连接处于一个中间状态，即没成功，也没失败。于是,服务器端如果在一定时间内没有收到的TCP会重发ACK。在Linux下，默认重试次数为5次,重试的间隔时间从1s开始每次都翻倍,5次的重试时间间隔为1s,2s,4s,8s,16s,总共31s,第5次发出后还要等32s都知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 2^6 -1 = 63s，TCP才会把断开这个连接。 关于SYN Flood攻击。一些恶意的人就为此制造了SYN Flood攻击——给服务器发了一个SYN后，就下线了，于是服务器需要默认等63s才会断开连接，这样，攻击者就可以把服务器的syn连接的队列耗尽，让正常的连接请求不能处理。于是，Linux下给了一个叫tcp_syncookies参数来应对这个事——当SYN队列满了后,TCP会通过源地址端口、目标地址端口和时间戳打造出一个特别的Sequence Number发回去(又叫cookie),如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie发回来,然后服务端可以通过cookie建连接(即使你不在SYN队列中)。请注意,请先千万别用tcp_syncookies来处理正常的大负载的连接的情况。因为,synccookies是妥协版的TCP协议，并不严谨。对于正常的请求，你应该调整三个TCP参数可供你选择,第一个是:tcp_synack_retries可以用他来减少重试次数；第二个是:tcp_max_syn_backlog,可以增大SYN连接数;第三个是:tcp_abort_on_overflow处理不过来干脆就直接拒绝连接了。 TCP链接的终止—四次挥手挥手过程就很好理解了，TCP是双全工的。发送方和接收方都需要Fin和Ack。只不过，有一方是被动的，所以看上去就成了所谓的4次挥手。如果两边同时断连接，那就会就进入到CLOSING状态，然后到达TIME_WAIT状态。 A：兄弟我的数据传送完了B：收到了—-过了一会B的数据也传完了B：兄弟我数据传完了A：好的收到了 在里面需要注意的是:关于MSL和TIME_WAIT。我们注意到，在TCP的状态图中，从TIME_WAIT状态到CLOSED状态,有一个超时设置,这个超时设置是 2*MSL（RFC793定义了MSL为2分钟，Linux设置成了30s）为什么要这有TIME_WAIT？为什么不直接给转成CLOSED状态呢？主要有两个原因：1）TIME_WAIT确保有足够的时间让对端收到了ACK，如果被动关闭的那方没有收到Ack，就会触发被动端重发Fin，一来一去正好2个MSL，2）有足够的时间让这个连接不会跟后面的连接混在一起（你要知道，有些自做主张的路由器会缓存IP数据包，如果连接被重用了，那么这些延迟收到的包就有可能会跟新连接混在一起）。 关于TCP的长链接与短连接TCP的链接都是通过三次握手和四次挥手建立的，在一般情况下一般TCP是建立的短连接，一次数据传完就断开，这样也方便链接的管理。但是在某些需要频繁的交换数据的场景，这样就会浪费很多时间和资源在链接的建立和断开，所以这个时候就适合使用长连接进行通信。 短连接一般短连接是client向server发起连接请求，和server通过三次握手，建立连接。client和server两边进行一次通信，然后一次读写就完成了。通常这时候双方都可以发送FIN进行关闭连接，但是一般情况下都是client先进行发送，一般server不会回复完ACK后立即关闭连接，server端会在数据发送完后发送FIN进行关闭，一般一个链接进行一次通信，这样链接的管理比较方便，不需要额外的控制手段。 长链接长链接的情况比短连接复杂，client和server建立链接后，进行一次通信，在通信完成后，双方都不会发送FIN关闭链接，后续通信也可以继续使用该链接。而且链接的保活一般都是在server端进行的，在不进行通信的时候，server是处于一个半链接的状态，这个时候的server应该通过某种办法去获取client的状态，用来判断这个链接是否该关闭，不然对server资源占用是非常严重的，而且也非常没有必要，这个也叫TCP的保活。TCP的保活一般有两种办法:1、在应用层建立心跳机制:client在隔一段时间向server发送一次心跳包(一般都是很小的包，或者只包含包头的一个空包)，让server知道此时client的状态，server可以不对心跳包进行处理。2、TCP协议的KeepAlive机制：当建立一个TCP连接时设置后keepalive后，就会将一系列的定时器与该连接相关联。这些定时器中某些用于处理keepalive过程。当keepalive定时器变为0时，client会发送一个keepalive 探针包（probe packet）到server，server在收到包后，会回应一个ACK。 参考:TCP 的那些事儿（上）","categories":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://yoursite.com/categories/TCP-IP/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"http://yoursite.com/tags/TCP/"}]},{"title":"我理解的TCP协议(二)---超时与重传","slug":"我理解的TCP协议(二)---超市与重传","date":"2017-02-08T09:54:51.000Z","updated":"2019-05-16T08:47:40.967Z","comments":true,"path":"2017/02/08/我理解的TCP协议(二)---超市与重传/","link":"","permalink":"http://yoursite.com/2017/02/08/我理解的TCP协议(二)---超市与重传/","excerpt":"原文TCP的可靠性不止建立在建立一个稳固的链接上，还有就是数据包丢失的重传机制,和防止网络波动的拥塞处理机制,这些都是慢慢发展而来的。要先了解TCP的重传和拥塞处理,需要先了解两个很常见的变量–RTT和RTO,这两个是对重传和拥塞很重要的概念。 RTT(Round Trip Time):就是发送一个数据包的往返时间的测量,由于路由器和网络流量均会变化，因此我们认为这个时间可能经常会发生变化，TCP应该跟踪这些变化并相应地改变其超时时间。RTO(Retransmission TimeOut):重传超时时间,是根据RTT计算得到的。 重传在重传机制中，首先在介绍重传的几个机制前，要注意。接收端给发送端的Ack确认只会确认最后一个连续的包。比如：发送端发了1,2,3,4,5一共五份数据，接收端收到了1,2,于是回ack 3,然后收到了4(注意此时3没收到，3丢失)此时的TCP会怎么办?我们要知道,因为正如前面所说的,SeqNum和Ack是以字节数为单位,所以ack的时候,不能跳着确认,只能确认最大的连续收到的包,不然,发送端就以为之前的都收到了。","text":"原文TCP的可靠性不止建立在建立一个稳固的链接上，还有就是数据包丢失的重传机制,和防止网络波动的拥塞处理机制,这些都是慢慢发展而来的。要先了解TCP的重传和拥塞处理,需要先了解两个很常见的变量–RTT和RTO,这两个是对重传和拥塞很重要的概念。 RTT(Round Trip Time):就是发送一个数据包的往返时间的测量,由于路由器和网络流量均会变化，因此我们认为这个时间可能经常会发生变化，TCP应该跟踪这些变化并相应地改变其超时时间。RTO(Retransmission TimeOut):重传超时时间,是根据RTT计算得到的。 重传在重传机制中，首先在介绍重传的几个机制前，要注意。接收端给发送端的Ack确认只会确认最后一个连续的包。比如：发送端发了1,2,3,4,5一共五份数据，接收端收到了1,2,于是回ack 3,然后收到了4(注意此时3没收到，3丢失)此时的TCP会怎么办?我们要知道,因为正如前面所说的,SeqNum和Ack是以字节数为单位,所以ack的时候,不能跳着确认,只能确认最大的连续收到的包,不然,发送端就以为之前的都收到了。 超时重传如果发送端决定死等3的ACK的话,等timeout后在重传3,然后接收端会回一个4(以为着3，4都收到了)。但是有个问题很严重。在等3的超时的时候，由于4已经发送了,但是接收端不会发送4的ACK。说明在等3的时候，发送端会悲观的认为4也丢了。这个时候就会有两种选择： 一种是仅重传第一个timeout的包。也就是第3份数据 第二种就是重传timeout后面所有的包 这两种方式有好也有不好。第一种会节省带宽，但是慢，第二种会快一点，但是会浪费带宽，也可能会有无用功。但总体来说都不好。因为都在等timeout，timeout可能会很长。 快速重传TCP引入了一种叫Fast Retransmit的算法,不以时间驱动,而以数据驱动重传。也就是说，如果包没有连续到达,就ack最后那个可能被丢了的包，如果发送方连续收到3次相同的ack，就重传。Fast Retransmit的好处是不用等timeout了再重传。比如：如果发送方发出了1，2，3，4，5份数据，第一份先到送了，于是就ack回2，结果2因为某些原因没收到，3到达了，于是还是ack回2，后面的4和5都到了，但是还是ack回2，因为2还是没有收到，于是发送端收到了三个ack=2的确认，知道了2还没有到，于是就马上重转2。然后，接收端收到了2，此时因为3，4，5都收到了，于是ack回6。示意图如下 Fast Retransmit只解决了一个问题，就是timeout的问题，它依然面临一个艰难的选择，就是，是重传之前的一个还是重传所有的问题。对于上面的示例来说，是重传#2呢还是重传#2，#3，#4，#5呢？因为发送端并不清楚这连续的3个ack(2)是谁传回来的？也许发送端发了20份数据，是#6，#10，#20传来的呢。这样，发送端很有可能要重传从2到20的这堆数据（这就是某些TCP的实际的实现）。可见，这是一把双刃剑。 Selective Acknowledgment（SACK） 方法不管是超时重传还是快熟重传都会面临一个重传一个还是重传所有的问题，这个时候可以使用SACK的方法来告知真正被丢失的包。要使用SACK的方式需要TCP的两端同时支持才行，可以通过tcp_sack参数打开这个功能(2.4后默认打开)SACK方法需要在TCP头里加一个SACK option的东西，ACK还是Fast Retransmit的ACK，SACK则是汇报收到的一系列的非连续的没有确认的seq range。参看下图：这样，在发送端就可以根据回传的SACK来知道哪些数据到了，哪些没有到，对没有收到的数据进行重传。 在接受端向发送端发送ack 时会带上sack option123456789101112131415161718TCP SACK OptionKind: 5Length: Variable +-------------+-------------+ | Kind = 5 | Length |+------------+------------+-------------+-------------+| Left Edge of list Block |+------------+------------+-------------+-------------+| Right Edge of list Block |+------------+------------+-------------+-------------+| |/ . . . /| |+------------+------------+-------------+-------------+| Left Edge of list Block |+------------+------------+-------------+-------------+| Right Edge of list Block |+------------+------------+-------------+-------------+ sack option 一般占40字节。其中kind 占4字节，length占4个字节，剩下的32字节，每8个字节就为一个sack段，来记录一个连续block的开始序号和结束序号，最多记录4组block。 注意：SACK会消费发送方的资源，试想，如果一个攻击者给数据发送方发一堆SACK的选项，这会导致发送方开始要重传甚至遍历已经发出的数据，这会消耗很多发送端的资源。可以参考TCP 选择性应答的性能权衡 D-SACK 方法Duplicate SACK又称D-SACK，其主要使用了SACK来告诉发送方有哪些数据被重复接收了。可以用tcp_dsack 参数进行开启（Linux2.4下默认开启）D-SACK 使用了 SACK 的第一个block来做标志： 如果SACK的第一个block的范围被ACK所覆盖，那么就是D-SACK 如果SACK的第一个block的范围被SACK的第二个段覆盖，那么就是D-SACK 引入了D-SACK，有这么几个好处： 可以让发送方知道，是发出去的包丢了，还是回来的ACK包丢了。 是不是自己的timeout太小了，导致重传。 网络上出现了先发的包后到的情况（又称reordering）。 网络上是不是把我的数据包给复制了。 知道这些东西可以很好得帮助TCP了解网络情况，从而可以更好的做网络上的流控。 参考:TCP 的那些事儿（上）TCP 的那些事儿（下）","categories":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://yoursite.com/categories/TCP-IP/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"http://yoursite.com/tags/TCP/"}]},{"title":"Java7的ConcurrentHashMap","slug":"Java7的ConcurrentHashMap","date":"2017-01-18T10:30:18.000Z","updated":"2019-05-16T08:47:45.660Z","comments":true,"path":"2017/01/18/Java7的ConcurrentHashMap/","link":"","permalink":"http://yoursite.com/2017/01/18/Java7的ConcurrentHashMap/","excerpt":"从HashMap并发的死循环可以知道,Hashmap是没办法在多线程的情况下使用的，为了解决这个问题，在Java4之前用的是hashtable,只是现在不推荐的。在Java5之后就比较推荐使用java.util.concurrent.ConcurrentHashMap，这个在多线程的情况下，也能有很好的性能。从这里引入了Java里面一类很重要的概念—并发。先解决完上一个问题。高并发下ConcurrentHashMap的结构。 并发的一些初步了解–synchronized和volatile在多线程的并发的情况下有安全的访问变量，为了解决这个问题引入一个机制—锁机制。让多线程不能同时访问一个共享变量。在并发过程中有需要简单的了解两个东西的含义。 Java中的synchronized的简单分析synchronized的用法要弄清晰一个问题:synchronized锁住的是代码还是对象？首先是一个被synchronized修饰的代码块","text":"从HashMap并发的死循环可以知道,Hashmap是没办法在多线程的情况下使用的，为了解决这个问题，在Java4之前用的是hashtable,只是现在不推荐的。在Java5之后就比较推荐使用java.util.concurrent.ConcurrentHashMap，这个在多线程的情况下，也能有很好的性能。从这里引入了Java里面一类很重要的概念—并发。先解决完上一个问题。高并发下ConcurrentHashMap的结构。 并发的一些初步了解–synchronized和volatile在多线程的并发的情况下有安全的访问变量，为了解决这个问题引入一个机制—锁机制。让多线程不能同时访问一个共享变量。在并发过程中有需要简单的了解两个东西的含义。 Java中的synchronized的简单分析synchronized的用法要弄清晰一个问题:synchronized锁住的是代码还是对象？首先是一个被synchronized修饰的代码块 12345678910111213141516private static int count; public SyncThread() &#123; count = 0; &#125; public void run() &#123; synchronized(this) &#123; for (int i = 0; i &lt; 3; i++) &#123; try &#123; System.out.println(Thread.currentThread().getName() + \":\" + (count++)); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; 在来看两段程序，这个概念可以清晰很多 1234567891011121314//第一段代码SyncThread syncThread = new SyncThread();Thread thread1 = new Thread(syncThread, \"Thread A\");Thread thread2 = new Thread(syncThread, \"Thread B\");thread1.start();thread2.start();//第二段代码SyncThread syncThread1 = new SyncThread();SyncThread syncThread2 = new SyncThread();Thread thread1 = new Thread(syncThread1, \"Thread A\");Thread thread2 = new Thread(syncThread1, \"Thread B\");thread1.start();thread2.start(); 这两段代码执行的结果: 1234567891011121314//第一段代码的执行结果，两个线程依次顺序执行Thread A:0 Thread A:1 Thread A:2 Thread B:3 Thread B:4 Thread B:5 //第二段代码的执行结果，两个线程轮流执行Thread A:0 Thread B:1 Thread A:2 Thread B:3 Thread A:4 Thread B:5 第一个结果是A，B两个线程按照锁的方式，依次执行。第二个结果是两个线程不受锁的控制交替执行，为什么会出现这个情况呢？主要是因为第一段代码中线程A和线程B都是访问syncThread这个一个对象，必须按照获得锁的顺序执行。但是在第二段代码中线程A访问的是syncThread1,线程B访问的是syncThread2,线程A执行的是syncThread1对象中的synchronized代码(run),线程B一样。这就可以知道synchronized锁住的是对象，这时会有两把锁分别锁定syncThread A对象和syncThread B对象，而这两把锁是互不干扰的，不形成互斥，所以两个线程可以同时执行。synchronized是一种同步锁它修饰的对象有以下几种： 修饰一个代码块，被修饰的代码块称为同步语句块，其作用的范围是大括号{}括起来的代码，上文的例子就是代码块，作用的对象是调用这个代码块的对象； 修饰一个方法，被修饰的方法称为同步方法，其作用的范围是整个方法，作用的对象是调用这个方法的对象； 修改一个静态的方法，其作用的范围是整个静态方法，作用的对象是这个类。 无论synchronized关键字加在方法上还是对象上，如果它作用的对象是非静态的，则它取得的锁是对象；如果synchronized作用的对象是一个静态方法或一个类，则它取得的锁是对类，该类所有的对象同一把锁。每个对象只有一个锁（lock）与之相关联，谁拿到这个锁谁就可以运行它所控制的那段代码 Java中的volatile的简单分析Volatile是轻量级的synchronized，它在多处理器开发中保证了共享变量的“可见性”。可见性的意思是当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。想要彻底的理解volatile就必须理解Java的内存模型这个会在下一篇里文章讲到。关于volatile要知道就是每当线程要访问一个被volatile修饰的变量时都会从内存中直接拉取，而不会从缓存中获取这个变量的值。 Hashtable和—-已经淘汰的遗留并发的HashMap简单说一下Hashtable和HashMap的区别：HashMap是非synchronized的适合在单线程下使用，并可以接受null(HashMap可以接受为null的键值(key)和值(value)，而Hashtable则不行)。Hashtable由于方法是由synchronized修饰的。可以在并发的情况下进行使用，只不过效率不高不建议使用。 Hashtable源码的简单分析Hashtable源码和HashMap差不多。先看put()方法 123456789101112131415161718192021222324252627282930313233343536 public synchronized V put(K key, V value) &#123; // Hashtable中不能插入value为null的元素！！！ if (value == null) &#123; throw new NullPointerException(); &#125; // “Hashtable中已存在键为key的键值对”,则用value替换 Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); int index = (hash &amp; 0x7FFFFFFF) % tab.length; Entry&lt;K,V&gt; entry = (Entry&lt;K,V&gt;)tab[index]; for(; entry != null ; entry = entry.next) &#123; if ((entry.hash == hash) &amp;&amp; entry.key.equals(key)) &#123; V old = entry.value; entry.value = value; return old; &#125; &#125; addEntry(hash, key, value, index); return null; &#125;private void addEntry(int hash, K key, V value, int index) &#123; //若“Hashtable中不存在键为key的键值对”，将“修改统计数”+1 modCount++; //若“Hashtable实际容量” &gt; “阈值”(阈值=总的容量 * 加载因子)则扩容 Entry&lt;?,?&gt; tab[] = table; if (count &gt;= threshold) &#123; rehash(); tab = table; hash = key.hashCode(); index = (hash &amp; 0x7FFFFFFF) % tab.length; &#125; //将新的key-value对插入到tab[index]处（即链表的头结点）. Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;) tab[index]; tab[index] = new Entry&lt;&gt;(hash, key, value, e); count++; &#125; 从源码看基本和HashMap差不多。解决哈希冲突的方法一样。但是不允许为null的键值对。get()都差不多就不分析了。 Hashtable淘汰的原因HashTable容器使用synchronized来保证线程安全,但在线程竞争激烈的情况下HashTable的效率非常低下。因为当一个线程访问HashTable的同步方法时,其他线程访问HashTable的同步方法时,可能会进入阻塞或轮询状态。如线程1使用put进行添加元素,线程2不但不能使用put方法添加元素,并且也不能使用get方法来获取元素,所以竞争越激烈效率越低。HashTable容器在竞争激烈的并发环境下表现出效率低下的原因是所有访问HashTable的线程都必须竞争同一把锁,那假如容器里有多把锁,每一把锁用于锁容器其中一部分数据,那么当多线程访问容器里不同数据段的数据时,线程间就不会存在锁竞争,从而可以有效的提高并发访问效率,这就是ConcurrentHashMap所使用的锁分段技术,首先将数据分成一段一段的存储，然后给每一段数据配一把锁,当一个线程占用锁访问其中一个段数据的时候,其他段的数据也能被其他线程访问。 Java7的ConcurrentHashMap的结构分析和锁分段技术现在在Java8优化了Java7的的锁分段技术。取消了segment和Java8的Hashmap的优化一样。现在看Java7的锁分段技术，毕竟还是很有思考价值的。Java8的ConcurrentHashMap分析会在另一篇博文里面Java7的ConcurrentHashMap的基本结构图,这个可以很清晰的认识到ConcurrentHashMap得内部存储结构。这个和HashMap的结构还是有很大差距的。不过有一点不会变的是:两者的本质都是数组和链表的结合Java7的ConcurrenHashMap类中有两个静态内部类HashEntry和Segment。HashEntry 用来封装映射表的键值对;Segment用来充当锁的角色,每个Segment对象守护整个散列映射表的若干个桶。每个桶是由若干个 HashEntry对象链接起来的链表。一个ConcurrentHashMap实例中包含由若干个Segment对象组成的数组。Segment 在某些意义上有点类似于HashMap了，都是包含了一个数组，而数组中的元素可以是一个链表。 HashEntry类12345678910111213static final class HashEntry&lt;K,V&gt; &#123; final K key; // 声明 key 为 final 型 final int hash; // 声明 hash 值为 final 型 volatile V value; // 声明 value 为 volatile 型 final HashEntry&lt;K,V&gt; next; // 声明 next 为 final 型 HashEntry(K key, int hash, HashEntry&lt;K,V&gt; next, V value) &#123; this.key = key; this.hash = hash; this.next = next; this.value = value; &#125; &#125; 在这个里面需要注意的是 key,hash,next节点都被声明为final型,这就意味着,发生了哈希冲突后,新来的节点只能插在头结点。而且链表原来的结构也没有被改变，插入新健 / 值对到链表中的操作不会影响读线程正常遍历这个链表。 value被声明为volatile变量。用volatile来保证多个线程对数据的可见性。就为get()不加锁打下基础。 Segment类12345678910111213141516171819202122232425262728293031323334353637static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; //在本 segment 范围内，包含的 HashEntry 元素的个数 transient volatile int count; //table 被更新的次数 transient int modCount; //当 table 中包含的 HashEntry 元素的个数超过本变量值时，触发 table 的再散列 transient int threshold; /** * table 是由 HashEntry 对象组成的数组 * 如果散列时发生碰撞，碰撞的 HashEntry 对象就以链表的形式链接成一个链表 * table 数组的数组成员代表散列映射表的一个桶 * 每个 table 守护整个 ConcurrentHashMap 包含桶总数的一部分 * 如果并发级别为 16，table 则守护 ConcurrentHashMap 包含的桶总数的 1/16 */ transient volatile HashEntry&lt;K,V&gt;[] table; //装载因子 final float loadFactor; Segment(int initialCapacity, float lf) &#123; loadFactor = lf; setTable(HashEntry.&lt;K,V&gt;newArray(initialCapacity)); &#125; /** * 设置 table 引用到这个新生成的 HashEntry 数组 * 只能在持有锁或构造函数中调用本方法 */ void setTable(HashEntry&lt;K,V&gt;[] newTable) &#123; // 计算临界阀值为新数组的长度与装载因子的乘积 threshold = (int)(newTable.length * loadFactor); table = newTable; &#125; //根据 key 的散列值，找到 table 中对应的那个桶（table 数组的某个数组成员） HashEntry&lt;K,V&gt; getFirst(int hash) &#123; HashEntry&lt;K,V&gt;[] tab = table; // 把散列值与 table 数组长度减 1 的值相“与”，得到散列值对应的 table 数组的下标然后返回 table 数组中此下标对应的 HashEntry 元素 return tab[hash &amp; (tab.length - 1)]; &#125; &#125; 在这个里面需要注意的是： Segment类是继承ReentrantLock类,这就是为了让Segment对象可以充当锁。每个Segment对象用来守护其(成员对象 table中)包含的若干个桶。 table是一个由HashEntry对象组成的数组。table数组的每一个数组成员就是散列映射表的一个桶。 count变量是一个计数器，它表示每个Segment对象管理的table数组(若干个HashEntry组成的链表)包含的HashEntry对象的个数。并且是volatile变量,所以当需要更新计数器时,不用锁定整个ConcurrentHashMap分段锁实现并发下的put()操作1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253 public V put(K key, V value) &#123; if (value == null) //ConcurrentHashMap中不允许用null作为映射值 throw new NullPointerException(); int hash = hash(key.hashCode()); // 计算键对应的散列码 // 根据散列码找到对应的 Segment return segmentFor(hash).put(key, hash, value, false); &#125; //使用 key 的散列码来得到 segments 数组中对应的 Segment final Segment&lt;K,V&gt; segmentFor(int hash) &#123; // 将散列值右移 segmentShift 个位，并在高位填充 0 // 然后把得到的值与 segmentMask 相“与” // 从而得到 hash 值对应的 segments 数组的下标值 // 最后根据下标值返回散列码对应的 Segment 对象 return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask]; &#125; //在 Segment 中执行具体的 put 操作 V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; lock(); // 加锁，这里是锁定某个Segment对象而非整个ConcurrentHashMap try &#123; int c = count; if (c++ &gt; threshold) &#123; // 如果超过再散列的阈值,执行再散列，table 数组的长度将扩充一倍 rehash(); &#125; HashEntry&lt;K,V&gt;[] tab = table; // 把散列码值与 table 数组的长度减 1 的值相“与” // 得到该散列码对应的 table 数组的下标值 int index = hash &amp; (tab.length - 1); // 找到散列码对应的具体的那个桶 HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) &#123; e = e.next; &#125; V oldValue; if (e != null) &#123; // 如果键 / 值对以经存在 oldValue = e.value; if (!onlyIfAbsent) &#123; e.value = value; // 设置 value 值 &#125; &#125; else &#123; // 键 / 值对不存在 oldValue = null; ++modCount; // 要添加新节点到链表中，所以 modCont 要加 1 // 创建新节点，并添加到链表的头部 tab[index] = new HashEntry&lt;K,V&gt;(key, hash, first, value); count = c; // 写 count 变量 &#125; return oldValue; &#125; finally &#123; unlock(); // 解锁 &#125; &#125; 在这个里面需要注意的是:这里的加锁操作是针对(键的hash值对应的)某个具体的Segment,锁定的是该Segment而不是整个ConcurrentHashMap。因为插入键值对的操作只是在这个Segment包含的某个桶中完成,不需要锁定整个ConcurrentHashMap。此时,其他写线程对另外15个Segment的加锁并不会因为当前线程对这个Segment的加锁而阻塞。同时,所有读线程几乎不会因本线程的加锁而阻塞,除非读线程刚好读到这个Segment中某个HashEntry的value域的值为null,此时需要加锁后重新读取该值。 小小的总结这次的并发下的优化的具体方向是根据一些试用场景优化的:除了少数插入操作和删除操作外，绝大多数都是读取操作，而且读操作在大多数时候都是成功的。原来的Hashtable的synchronized直接加锁的方式,会在put()操作的时候同时会阻塞其他线程的get()操作。ConcurrentHashMap就多次采用volatile变量来解决变量在JMM(Java内存模型)中对其他线程可见性。这也可以使volatile对synchronized锁的优化。用分段锁去优化synchronized的put()操作的阻塞。就在于减少多个线程对同一个锁的请求频率和减少线程对锁的持有时间,就是减小锁的细粒度来优化锁的阻塞。 参考:Java中Synchronized的用法探索 ConcurrentHashMap 高并发性的实现机制ConcurrentHashMap 的实现原理","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"session和cookie","slug":"session和cookie","date":"2016-12-22T10:35:35.000Z","updated":"2019-05-16T08:47:43.405Z","comments":true,"path":"2016/12/22/session和cookie/","link":"","permalink":"http://yoursite.com/2016/12/22/session和cookie/","excerpt":"基本认识首先有一点必须特别的清楚： 因为HTTP协议是无状态的，客户每次读取web页面时，服务器都打开新的会话，而且服务器也不会自动维护客户的上下文信息，对于一个浏览器发出的多次请求，WEB服务器无法区分 是不是来源于同一个浏览器，更别说是否是来自同一用户。为了保持用户的状态，有了两种机制，一般用户客户端的cookie机制，和用于服务器端的session机制，这两种机制都是为了保持状态，既有联系又有区别。 cookie基本实现机制现在的cookie是HTTP协议的一部分，一般存在HTTP的响应头，内容是一系列的键值对的形式，简单说：cookie就是服务器在用户的浏览器中存储的一小段文本文件（大小不能超过3K）不包含任何可执行代码，里面一般包含的是用户的登录信息之类的比较少的，用来验证用户是否合法（不止局限与此，cookie是用来记录状态的，也可以是购物的等一系列状态，让服务器知道我们浏览了那些地方，购物对那些感兴趣，一般很多广告都是根据这个东西来推送的，你在某购物网站买了一个东西，然后浏览别的网站，发现广告都是和你浏览的相关）。 cookie的内容主要包括：key-value,Expires（过期时间），path和domain。path和domain一起构成cookie的作用范围。&emsp;&emsp;&emsp;&emsp;现在的cookie，内容经过加密了cookie的实现流程： 浏览器向某个URL发起HTTP请求 （可以是任何请求，比如GET，POST等） 对应的服务器收到该HTTP请求，并做相应的响应（响应头和请求体两部分），在响应的头中加入Set-Cookie字段（设置相应的cookie，cookie是多个key-value组成的）","text":"基本认识首先有一点必须特别的清楚： 因为HTTP协议是无状态的，客户每次读取web页面时，服务器都打开新的会话，而且服务器也不会自动维护客户的上下文信息，对于一个浏览器发出的多次请求，WEB服务器无法区分 是不是来源于同一个浏览器，更别说是否是来自同一用户。为了保持用户的状态，有了两种机制，一般用户客户端的cookie机制，和用于服务器端的session机制，这两种机制都是为了保持状态，既有联系又有区别。 cookie基本实现机制现在的cookie是HTTP协议的一部分，一般存在HTTP的响应头，内容是一系列的键值对的形式，简单说：cookie就是服务器在用户的浏览器中存储的一小段文本文件（大小不能超过3K）不包含任何可执行代码，里面一般包含的是用户的登录信息之类的比较少的，用来验证用户是否合法（不止局限与此，cookie是用来记录状态的，也可以是购物的等一系列状态，让服务器知道我们浏览了那些地方，购物对那些感兴趣，一般很多广告都是根据这个东西来推送的，你在某购物网站买了一个东西，然后浏览别的网站，发现广告都是和你浏览的相关）。 cookie的内容主要包括：key-value,Expires（过期时间），path和domain。path和domain一起构成cookie的作用范围。&emsp;&emsp;&emsp;&emsp;现在的cookie，内容经过加密了cookie的实现流程： 浏览器向某个URL发起HTTP请求 （可以是任何请求，比如GET，POST等） 对应的服务器收到该HTTP请求，并做相应的响应（响应头和请求体两部分），在响应的头中加入Set-Cookie字段（设置相应的cookie，cookie是多个key-value组成的） 浏览器收到来自服务器的HTTP响应 浏览器在响应头中发现存在Set-Cookie字段，就会将相应的cookie(key-value)保存在内存或者硬盘中。需要注意的是Set-Value字段可以包含多个cookie,每一项都可以指定过期时间，默认的过期的时间是用户浏览器关闭的时候 浏览器下次给该服务器发送HTTP请求时，会将服务器设置的cookie附加在HTTP请求头Cookie中浏览器可以存储多个不同域名下的Cookie，但只发送当前请求的域名曾经指定的域名，这个可以在Set-Cookie中指定 服务器收到这个HTTP请求，发现请求头中有Cookie字段，就知道这个用户的状态。获取相应的信息进行响应。这就是整个基本的cookie机制。保存了用户的操作状态，但是还需要注意的是,cookies是通过明文传递。在HTTP包中容易被劫持和伪造，是不安全的，不应该存一些比较重要的东西。还有就是cookie在整个会话都会在HTTP的请求中，增加了流量。 session的基本实现机制有一个session是不能改变的，是为了维持住HTTP的状态，所以在用户每次发起HTTP请求的时候，都需要让服务器知道是那个用户发起的这个请求，然后查找这个用户的状态，在进行相应的处理。session的实现基于这点，就需要一个唯一的ID标志某个用户（session）然后在这个ID中对应多个键值对来保证用户的状态，所以前后端只需要传递一个sessionId，服务器就可找到对应的状态（这个对应的键值对可以存在redies或者数据库中）。前后端传递值基本有三种：一种是直接写在URL中，一种通过表单中的隐藏域来提交，还有一种是现在流行的做法，通过在cookie中设置一个键值对jsessionId=${sessionId}在传递。现在第一二种都不是很建议这么做，当然在浏览器禁用的情况下也可以通过前面两种来传递，不过一般浏览器都支持使用cookie的方式。 两种方式的区别和联系 cookie数据存放在客户的浏览器上，session数据放在服务器上。 cookie不是很安全，别人可以分析存放在本地的cookie并进行cookie欺骗，考虑到安全应当使用session。 session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能考虑到减轻服务器性能方面，应当使用cookie。 单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。联系是：两个都是用来保持HTTP协议状态的方式，一种是客户端的实现，一种是服务器端的实现。但是session可以依赖于cookie来传递sessionId 一个小项目例子–在微信中开发的小程序（公众号自动回复）里面的session问题首先简单描述下小项目:用户在公众号中输入某一个触发关键词（项目里面的例子是：绑定），然后就进入绑定所涉及的流程。用户在公众中输入触发词，是由微信的服务器进行响应，然后转发到程序的服务器。程序的服务器在把处理的结果（用规定的格式）传递给微信的服务器，由微信的服务器进行响应给用户。整个项目用golang开发，简单的使用了beego框架。 基于session来实现（初始版）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112func (c *MainController) Dispatch() &#123; //进行请求的分发，和request数据的解析,POST w := new(models.WeixinUser) xml.Unmarshal(c.Ctx.Input.RequestBody,&amp;w) //第一步是判断是否为开启逻辑的语句，同一个逻辑只能同时开启一次 str:=w.Content sc:=c.GetSession(\"status-count\").(int) switch str &#123; case \"绑定\": //如果匹配进入绑定，判断是否同时开启两次 str0:=\"\" binds:=assertionInt(c.GetSession(\"bindstep\")) if binds==-1&#123; c.SetSession(\"bindstep\",int(1)) sc++; c.SetSession(\"status-count\",int(sc)) c.SetSession(\"status-\"+strconv.Itoa(sc),string(\"bind\")) _,str0=bind(c,w) &#125; if str0==\"\"&#123; str0=\"已经进入绑定流程\" &#125; prints(c,w,str0) return &#125; //第二步判断有多少个session保持者状态，从0开始计数,输入的数据从最上面的应用进行匹配处理 if sc &gt;=0 &#123;//判断是否有触发的逻辑 for i:=sc;i&gt;=0;i--&#123;//进行逻辑匹配 str2:=c.GetSession(\"status-\"+strconv.Itoa(i)).(string) if str2!=\"\"&#123; str1:=\" \"//进行默认的逻辑处理，不做回应 switch str2 &#123; case \"bind\": code,src:=bind(c,w)//code用来处理完成逻辑后的删除session的作用 if code==1&#123; c.DelSession(\"status-\"+strconv.Itoa(i)) c.SetSession(\"status-count\",int(sc-1)) sc--; &#125; str1=src &#125; if str1 != \" \"&#123;//如果进行处理就退出逻辑 prints(c,w,str1) return &#125; if str1 ==\" \"&amp;&amp;i==0&#123; str1=\"输入格式错误\" prints(c,w,str1) return &#125; &#125; &#125; &#125; str=\"输入：绑定，可以进入绑定流程\" prints(c,w,str)&#125;func bind(c *MainController,w *models.WeixinUser) (int,string) &#123;//进行绑定请求的处理，如果匹配不上，退出同时开始另一个逻辑的匹配 step:=c.GetSession(\"bindstep\").(string)//内部逻辑计数器，记住用户的处理的位置，从1开始计数 if step==1||step==2||step==3||step==4&#123; switch step &#123; case 1://用户输入进入词，进入逻辑 c.SetSession(\"bindstep\",int(2)) return 0,\"请输入手机号，进行绑定\" case 2://用户输入了手机号，发送短信，获取验证码 //todo 验证手机号格式并且发短信验证验证码 ok:=validatePhone(w.Content) if !ok&#123; return 0,\"手机号格式不正确，请重新输入\" &#125; alidayu.AppKey=\"*******\" alidayu.AppSecret=\"**************\" alidayu.UseHTTP=true str:=randNum()//生成随机4位数字 success,_:=alidayu.SendSMS(w.Content,\"德玛西亚\",\"********\", `&#123; \"code\":\"`+str+`\"&#125;`) if !success&#123; return 0,\"验证码发送失败，请重新输入手机号\" &#125; c.SetSession(\"rand\",str) f:=models.Fluge&#123;&#125; f.Openid=w.FromUserName f.Phone=w.Content c.SetSession(\"fluge\",f) c.SetSession(\"bindstep\",int(3)) return 0,\"验证码已发送，请输入验证码完成绑定\" case 3://进行验证码的验证，成功就开始绑定 if w.Content==c.GetSession(\"rand\").(string) &#123; f:=c.GetSession(\"fluge\").(*models.Fluge) c.DelSession(\"fluge\") c.DelSession(\"rand\") flag,_:=models.CheckUser(f) if flag &#123; str3, err := models.AddUser(f) if err != nil &#123; return 0, str3 &#125; c.SetSession(\"bindstep\", int(4)) return 0, str3 &#125; c.SetSession(\"bindstep\",int(2)) return 0,\"手机号无法重复绑定，请重新输入手机号\" &#125; return 0,\"验证码错误，请重新输入\" case 4://用户已经完成绑定，等待退出 if w.Content==\"8\" &#123; c.DelSession(\"bindstep\") return 1,\"谢谢使用\" &#125; return 0,\"绑定完成，请输入8退出\" &#125; &#125; return 0,\" \"&#125; 现在这个程序是执行不了的。在beego中默认传递sessionId是cookie。但如果我在程序中必须使用session保持用户的状态（不然流程没办法继续下去）。两个服务器之间的交互式没有办法传递cookie。所以就会出现在一直在第一个流程，无法进入第二个流程。 解决首先明白一点，sessionId的作用是一个唯一标识符，用来标记同一个用户。但是在微信的整个架构中有一个跟sessionId很类似的东西:openid:用户对于某个公众号唯一的标识。所以在微信服务器向程序的服务器提交POST消息市本身也会自带这个openid。这样就为解决session提供了遍历。不需要额外去产生和传递sessionId。直接使用openid来作为用户的唯一标识符。然后对于sessionId对应的具体内容我选择了方便的redis来存储实现代码–直接复写了beego的Getseeion和SetSession方法 12345678910111213141516171819202122232425262728293031func (c *MainController)initSession(sid string) &#123; config := &amp;redissession.SessionConfig&#123; Prefix:\"lyfluge-\", RedisHost:\"**********\", RedisPassword:\"f***********\", LifeTime: 60 * time.Second, &#125; c.sesion = redissession.NewSession(\"redis\",config) c.sesion.SetSessionID(sid) c.sesion.Start()&#125;func (c *MainController)storeSession() &#123; c.sesion.Store()&#125;func (c *MainController) SetSession(str string,value interface&#123;&#125;)interface&#123;&#125;&#123; return c.sesion.Set(str,value)&#125;func (c *MainController) GetSession(str string) interface&#123;&#125;&#123; return c.sesion.Get(str)&#125;func (c *MainController) DelSession(str string) interface&#123;&#125;&#123; return c.sesion.Delete(str)&#125;//在Dispatch函数中取到对应的sessionId，然后进行状态判断func (c *MainController) Dispatch() &#123; //进行请求的分发，和request数据的解析.POST w := new(models.WeixinUser) xml.Unmarshal(c.Ctx.Input.RequestBody,&amp;w) c.initSession(w.FromUserName) /..../&#125; 完整代码(包括微信golang的接入,大鱼短信,beego,session-redis的具体实现): 总结session中的sessionId是用来标志唯一用户的。通过找到这个用户来判断用户的状态 参考:Cookie/Session的机制与安全","categories":[{"name":"web","slug":"web","permalink":"http://yoursite.com/categories/web/"}],"tags":[{"name":"session","slug":"session","permalink":"http://yoursite.com/tags/session/"},{"name":"cookie","slug":"cookie","permalink":"http://yoursite.com/tags/cookie/"}]},{"title":"HashMap的并发死循环","slug":"HashMap并发的死循环","date":"2016-12-15T09:52:18.000Z","updated":"2019-05-16T08:43:14.957Z","comments":true,"path":"2016/12/15/HashMap并发的死循环/","link":"","permalink":"http://yoursite.com/2016/12/15/HashMap并发的死循环/","excerpt":"HashMap从设计上来说就不适合在并发的情况的下使用,因为HashMap每次在put()时，总会检查一遍对应桶的容量，如果桶满了，或者超过了设定的值，就会reserve()来进行扩容,然后通过get()来取出相应的值。这个过程在单线程下是没什么问题的，但是如果在并发的条件下，多个线程同时reserve桶，然后有线程这个时候执行get()就有可能产生死循环，造成CPU的100%占用，具体等会看源码。在Java里面有一个很老的hashtable就是加了锁的HashMap。现在Java中多线程里一般使用ConcurrentHashMap，至于为什么。会在下一篇博文里分析。 HashMap的rehash源代码put()方法的Java8源码分析看我的Java里的hashMap和golang里的map，在Java8中优化了扩容的hash算法，更加高效。在这分析死循环用的是Java7的源码。更加清晰点。","text":"HashMap从设计上来说就不适合在并发的情况的下使用,因为HashMap每次在put()时，总会检查一遍对应桶的容量，如果桶满了，或者超过了设定的值，就会reserve()来进行扩容,然后通过get()来取出相应的值。这个过程在单线程下是没什么问题的，但是如果在并发的条件下，多个线程同时reserve桶，然后有线程这个时候执行get()就有可能产生死循环，造成CPU的100%占用，具体等会看源码。在Java里面有一个很老的hashtable就是加了锁的HashMap。现在Java中多线程里一般使用ConcurrentHashMap，至于为什么。会在下一篇博文里分析。 HashMap的rehash源代码put()方法的Java8源码分析看我的Java里的hashMap和golang里的map，在Java8中优化了扩容的hash算法，更加高效。在这分析死循环用的是Java7的源码。更加清晰点。 123456789101112131415161718192021222324252627282930313233343536void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; //创建一个新的Hash Table Entry[] newTable = new Entry[newCapacity]; //将Old Hash Table上的数据迁移到New Hash Table上 transfer(newTable, initHashSeedAsNeeded(newCapacity)) table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); &#125;/** * 将当前table的Entry转移到新的table中 */void transfer(Entry[] newTable)&#123; Entry[] src = table; int newCapacity = newTable.length; //下面这段代码的意思是:从OldTable里摘一个元素出来，然后放到NewTable中 for (int j = 0; j &lt; src.length; j++) &#123; Entry&lt;K,V&gt; e = src[j]; if (e != null) &#123; src[j] = null; do &#123; Entry&lt;K,V&gt; next = e.next; //在新的table 中求得适合插入的位置 int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; while (e != null);// 可能导致死循环 &#125; &#125;&#125; 在单线程中的执行流程其实是很直观的:先对要插入的元素进行哈希，在数组中找到相应的位置，如果发生冲突就变成链表存储，在看桶有没有满。有就进resize()扩容操作。但是在多线程的时候由于扩容操作产生环形链，会造成get()方法命中时—-Infinite Loop,然后CPU爆炸。 举例分析(网上一个很经典的例子–引用自酷壳)假设我们的hash算法是简单的key mod一下表的大小(即数组的长度),现在有两个线程：一个蓝色标注，一个红色标注。关键代码在transfer()中把旧的table的Entry转移到新的table中的时候 1234567do &#123; Entry&lt;K,V&gt; next = e.next;&lt;--假设红色线程执行到这里就被调度挂起了,蓝色线程全部执行 int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next;&#125; while (e != null); 两个线程在蓝色线程执行完后的情况。这个时候红色线程中的e指向了key(3),而next指向了key(7),但是在蓝色线程中链表已经扩容完成,并且链表的顺序被反转 ,这个时候就有了环链的征兆了。e的下一个节点本来是next,经过蓝色线程扩容后变成了next下一个节点是e。就有很大的几率产生环形链。接着看,这个时候红色线程得到了执行的机会.被调度回来进行执行，先是执行newTalbe[i] = e;,然后是e = next，导致了e指向了key(7),而下一次循环的next = e.next导致了next指向了key(3)。然后红色线程接着工作,把key(7)摘下来，放到newTable[i]的第一个,然后把e和next往下移。然后重点来了：e.next = newTable[i]导致key(3).next指向了key(7)。但是此时的key(7).next 已经指向了key(3),环形链表就这样出现了。于是,当我们的线程一调用到,HashTable.get(11)时,悲剧就出现了——Infinite Loop。 参考：疫苗：Java HashMap的死循环不正当使用HashMap导致cpu 100%的问题追究","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"跨域","slug":"跨域","date":"2016-12-14T13:05:01.000Z","updated":"2019-04-24T06:43:52.000Z","comments":true,"path":"2016/12/14/跨域/","link":"","permalink":"http://yoursite.com/2016/12/14/跨域/","excerpt":"同源策略这套安全策略由Netscape提出，并延续至今。它规定：JavaScript脚本只能访问与其同一来源的资源(现在很多资源是通过ajax发起异步请求来获取的，如果没有跨域这个是禁止的)。所谓同源是指，域名，协议，端口相同。不同源的客户端脚本(javascript、ActionScript)在没明确授权的情况下，不能读写对方的资源。严格隔离不相关的网站提供的内容，防止客户端数据机密性或完整性丢失。假设你已经成功登录Gmail服务器，同时在同一个浏览器访问恶意站点（另一个浏览器选项卡）。没有同源策略，攻击者可以通过JavaScript获取你的用户信息，你的邮件以及其他敏感信息，比如说阅读你的私密邮件，发送虚假邮件，看你的聊天记录等等。假如把这个换成银行账户，那就很恐怖了。可以说同源策略是现如今浏览器安全的基石。但是如果不能突破同源策略，把所有的资源放在同一服务器下，现在看来是不现实，必须有一中方式去平衡这种安全和便捷的机制–跨域。现在一般的跨域使用的是CORS(基本所有浏览器支持)和JSONP(一些比较的老的应用使用)。 CROS跨域CORS是一个W3C标准，全称是”跨域资源共享”(Cross-origin resource sharing)。它允许浏览器向跨源服务器,发出XMLHttpRequest请求，从而克服了AJAX只能同源使用的限制。简单说一下我对CROS的理解。就相当于我想跟一个邻居借东西(浏览器向服务器发送跨域请求)。我首先要去敲门，然后就是几种情况，一种是邻居家里你敲门没有反应(服务器端没有设置跨域)，你跟不知道邻居家里的具体情况，借东西肯定是失败的。一种是邻居进行了应答，但是告诉你我跟你不熟，不借东西给你。另外一种就是邻居进行了应答，并借给你东西。","text":"同源策略这套安全策略由Netscape提出，并延续至今。它规定：JavaScript脚本只能访问与其同一来源的资源(现在很多资源是通过ajax发起异步请求来获取的，如果没有跨域这个是禁止的)。所谓同源是指，域名，协议，端口相同。不同源的客户端脚本(javascript、ActionScript)在没明确授权的情况下，不能读写对方的资源。严格隔离不相关的网站提供的内容，防止客户端数据机密性或完整性丢失。假设你已经成功登录Gmail服务器，同时在同一个浏览器访问恶意站点（另一个浏览器选项卡）。没有同源策略，攻击者可以通过JavaScript获取你的用户信息，你的邮件以及其他敏感信息，比如说阅读你的私密邮件，发送虚假邮件，看你的聊天记录等等。假如把这个换成银行账户，那就很恐怖了。可以说同源策略是现如今浏览器安全的基石。但是如果不能突破同源策略，把所有的资源放在同一服务器下，现在看来是不现实，必须有一中方式去平衡这种安全和便捷的机制–跨域。现在一般的跨域使用的是CORS(基本所有浏览器支持)和JSONP(一些比较的老的应用使用)。 CROS跨域CORS是一个W3C标准，全称是”跨域资源共享”(Cross-origin resource sharing)。它允许浏览器向跨源服务器,发出XMLHttpRequest请求，从而克服了AJAX只能同源使用的限制。简单说一下我对CROS的理解。就相当于我想跟一个邻居借东西(浏览器向服务器发送跨域请求)。我首先要去敲门，然后就是几种情况，一种是邻居家里你敲门没有反应(服务器端没有设置跨域)，你跟不知道邻居家里的具体情况，借东西肯定是失败的。一种是邻居进行了应答，但是告诉你我跟你不熟，不借东西给你。另外一种就是邻居进行了应答，并借给你东西。要了解CROS跨域，首先需要知道浏览器在ajax发起跨域请求的时候做了什么事。每次浏览器检查到这个请求是跨域请求时,会在请求的头部添加一些附加的头信息,根据请求的不同,有时会多发起一次请求但是这些用户是感觉不到，前端的ajax调用也没有发什么变化,改变的是服务器端的回应。所以cros跨域由于浏览器的支持，现在只要在服务器端，也就是后端进行配置就可以了。 cros分类浏览器将cros的跨域请求分为两种:一种是简单请求，一种的非简单请求，两种的区别就是在发起非简单请求的时候，浏览器会在请求的前面先发起一次预请求，看请求的后端是否允许当前这个域名和这个方法进行访问。 1234567891011简单请求(不满足以下条件的都是非简单请求):(1)请求方法是以下三种方法之一:HEADGETPOST(2)HTTP的头信息不超出以下几种字段:AcceptAccept-LanguageContent-LanguageLast-Event-IDContent-Type:只限于三个值application/x-www-form-urlencoded 或 multipart/form-data 或text/plain cros的简单请求对于简单请求的cros跨域请求,浏览器会在就是在头信息之中，增加一个Origin字段用来说明,本次请求来自哪个源(协议 + 域名 + 端口)服务器根据这个值，决定是否同意这次请求。如果Origin的字段在服务器端允许的范围内,服务器成功响应,会在返回的头信息中多几个字段 123456//该字段是必须的。它的值要么是请求时Origin字段的值，要么是一个*，表示接受任意域名的请求。Access-Control-Allow-Origin: http://api.bob.com//该字段可选。它的值是一个布尔值，表示是否允许发送CookieAccess-Control-Allow-Credentials: true//该字段可选。Access-Control-Expose-Headers: FooBar 如果Origin指定的域名不在许可范围内。服务器也会正常的返回HTTP的回应(状态吗有可能是200)，只是头信息里面不会增加上面的字段。浏览器收到回应后 会检测是否有Access-Control-Allow-Origin字段，如果没有回抛出一个错误，被XMLHttpRequest的onerror回调函数捕获 非简单请求非简单请求就是不满足简单请求条件的都是非简单请求，值得注意的是Content-Type: application/josn都是非简单请求。浏览器如果检测到发起的请求是非简单请求，会在正式发起HTTP请求前,浏览器会自动发起一次HTTP查询请求，称为”预检”请求（preflight）。预请求的方法是OPTIONS,这个方法和GET,POST等方法是一样的。这个方法表示请求是用来询问的服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些HTTP动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的XMLHttpRequest请求，否则就报错。 1234567891011121314151617181920212223242526272829303132一个预检请求OPTIONS /cors HTTP/1.1//表示请求来自哪个源。Origin: http://api.bob.com//该字段是必须的，用来列出浏览器的CORS请求会用到哪些HTTP方法，这个是PUT。Access-Control-Request-Method: PUT//该字段是一个逗号分隔的字符串，指定浏览器CORS请求会额外发送的头信息字段，上例是X-Custom-Header。Access-Control-Request-Headers: X-Custom-HeaderHost: api.alice.comAccept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0...预检请求允许,服务器端的回应HTTP/1.1 200 OKDate: Mon, 01 Dec 2008 01:15:39 GMTServer: Apache/2.0.61 (Unix)//表示http://api.bob.com可以请求数据。该字段也可以设为*，表示同意任意跨源请求。Access-Control-Allow-Origin: http://api.bob.com//该字段必需，表明服务器支持的所有跨域请求的方法。Access-Control-Allow-Methods: GET, POST, PUTAccess-Control-Allow-Headers: X-Custom-HeaderContent-Type: text/html; charset=utf-8Content-Encoding: gzipContent-Length: 0Keep-Alive: timeout=2, max=100Connection: Keep-AliveContent-Type: text/plain;预检请求被否定时,跟简单请求一样会回复一个正常的HTTP请求,然后浏览器检查，被被XMLHttpRequest对象的onerror回调函数捕获就会报错XMLHttpRequest cannot load http://api.alice.com.Origin http://api.bob.com is not allowed by Access-Control-Allow-Origin. 一旦服务器通过了”预检”请求，以后每次浏览器正常的CORS请求，就都跟简单请求一样，会有一个Origin头信息字段。服务器的回应，也都会有一个Access-Control-Allow-Origin头信息字段。 beego的跨域在工作中用beego框架遇到的跨域问题的解决 123456789101112func main() &#123; beego.InsertFilter(\"*\", beego.BeforeRouter,cors.Allow(&amp;cors.Options&#123; //允许的访问的域名 AllowOrigins: []string&#123;\"*\"&#125;, //允许的访问的方法 AllowMethods: []string&#123;\"OPTIONS\",\"GET\",\"PUT\",\"DELETE\",\"POST\"&#125;, AllowHeaders: []string&#123;\"Origin\"&#125;, ExposeHeaders: []string&#123;\"Content-Length\"&#125;, AllowCredentials: true, &#125;)) beego.Run()&#125; JSONP的简介CORS与JSONP的使用目的相同，但是比JSONP更强大。JSONP只支持GET请求，CORS支持所有类型的HTTP请求。JSONP的优势在于支持老式浏览器，以及可以向不支持CORS的网站请求数据。 参考:浏览器的同源策略及突破方法跨域资源共享 CORS 详解","categories":[{"name":"Web","slug":"Web","permalink":"http://yoursite.com/categories/Web/"}],"tags":[{"name":"cros","slug":"cros","permalink":"http://yoursite.com/tags/cros/"}]},{"title":"ICMP协议和UDP协议","slug":"ICMP协议和UDP协议","date":"2016-12-12T14:46:51.000Z","updated":"2019-05-16T08:47:50.096Z","comments":true,"path":"2016/12/12/ICMP协议和UDP协议/","link":"","permalink":"http://yoursite.com/2016/12/12/ICMP协议和UDP协议/","excerpt":"ICMP网络控制报文协议ICMP经常被认为是IP层的一个组成部分,它传递差错报文以及其他需要注意的信息。ICMP报文通常被IP层或更高层协议（UDP,TCP）使用。ICMP报文是在IP数据报内部传输的。由于IP是不可靠的协议，不能保证IP数据报能够成功到达目的主机，无法进行差错控制。但是这些信息会由ICMP将错误信息封包，然后传递给主机，让主机有处理错误的机会。ICMP数据报由8bit的错误类型和8bit的代码（表示制定类型中的一个功能，如果只有一个功能，代码就置0）以及16bit的校验和组成，检验和字段覆盖整个ICMP报文。ICMP报文大致可以分为：差错报文和查询报文。因为对ICMP的差错报文需要做一些特殊响应，需要进行区分。比如在对差错报文进行响应的时候，永远不会产生另一个ICMP差错报文，防止不断的产生差错一直循环。同时一下几种情况也不会产生ICMP差错报文： ICMP差错报文不会产生 目的地址是广播地址或多播地址的IP数据报 作为链路层广播的数据报 不是IP分片的第一片 源地址不是单个主机的数据报","text":"ICMP网络控制报文协议ICMP经常被认为是IP层的一个组成部分,它传递差错报文以及其他需要注意的信息。ICMP报文通常被IP层或更高层协议（UDP,TCP）使用。ICMP报文是在IP数据报内部传输的。由于IP是不可靠的协议，不能保证IP数据报能够成功到达目的主机，无法进行差错控制。但是这些信息会由ICMP将错误信息封包，然后传递给主机，让主机有处理错误的机会。ICMP数据报由8bit的错误类型和8bit的代码（表示制定类型中的一个功能，如果只有一个功能，代码就置0）以及16bit的校验和组成，检验和字段覆盖整个ICMP报文。ICMP报文大致可以分为：差错报文和查询报文。因为对ICMP的差错报文需要做一些特殊响应，需要进行区分。比如在对差错报文进行响应的时候，永远不会产生另一个ICMP差错报文，防止不断的产生差错一直循环。同时一下几种情况也不会产生ICMP差错报文： ICMP差错报文不会产生 目的地址是广播地址或多播地址的IP数据报 作为链路层广播的数据报 不是IP分片的第一片 源地址不是单个主机的数据报 ICMP查询报文： ping查询 子网掩码查询：用于无盘工作站在初始化自身的时候初始化子网掩码 时间戳查询：同步时间 ICMP应用—pingping是利用ICMP协议报来侦测另一个主机是否可达。原理就是用类型码为0的ICMP发请求，收到请求的主机则用类型码为8的ICMP进行回应。ping程序用来计算间隔时间，并计算有多少个包被送达。 ping给出来了传送的时间和TTL的数据。 ping还给我们一个看主机到目的主机陆游的机会。因为，ICMP的ping请求在经过路由器的时候，路由器会把自己的IP放到数据报中，而最后主机则会把这个ip列表复制到回应ICMP数据包发回给主机。但很重要的一点IP头所能记录的信息是非常有限。 这样就有了另一个充分利用TTL数据的应用Traceroute ICMP应用—TracerouteTraceroute是用来侦测主机到目的主机之间所经路由情况的重要工具，也是最便利的工具。Traceroute基本原理原理：它收到目的主机的IP后，首先给目的主机发送一个TTL=1的UDP数据报，而经过第一个的路由器收到数据报后，就会把TTL减1，这样TTL就会变为0.路由器就会抛弃数据报，并向主机发送目的主机不可达的ICMP数据报。然后主机就会发送TTL=2的数据报，如此往复直到到达目的主机。这样Traceroute就拿到了所有经过的路由器的IP。 UDP协议基本认识UDP是一个简单的面向数据报的传输层协议,UDP为网络层以上和应用层以下提供了一个简单的接口,传输方式”Best Effort”。UDP不用建立链接,它一旦把应用程序发给网络层的数据发送出去,就不保留备份。所以也就不提供超时重传，出错重传等功能。属于不可靠的协议。UDP其实可以看做IP协议暴露在传输层的一个接口。传输层和网络层的区别在于:传输层是提供端到端的服务的。打个比方:小明(进程A)在M市要去寄一封信给在N市的小芳(进程B)，其中邮局就统一把很多的信，用车从M运到N市(网络层)。最后由邮递员(传输层)进行最后一步把小明的信送到小芳的家中。UDP可以看做IP协议在传输层的“傀儡”。UDP的数据包分为头部和数据。UDP的数据报需要经过IP协议的封装，然后通过IP协议传输到目的电脑，随后拆封，并将信息送到相应端口的。 校验和这在UDP中是一个可选的选项，UDP校验和覆盖UDP协议头和数据，这和IP的校验和是不同的，IP协议的校验和只是覆盖IP数据头。UDP和TCP都包含一个伪首部，伪首部包含IP地址，目的是让UDP两次检查数据是否已经正确到达目的地，如果发送端没有打开检验和选项，而接收端计算检验和有差错，那么UDP数据将会被悄悄的丢掉（不保证送达），而不产生任何差错报文。","categories":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://yoursite.com/categories/TCP-IP/"}],"tags":[{"name":"ICMP","slug":"ICMP","permalink":"http://yoursite.com/tags/ICMP/"},{"name":"UDP","slug":"UDP","permalink":"http://yoursite.com/tags/UDP/"}]},{"title":"Java里的HashMap和golang里的map","slug":"Java里的hasMap和golang里的map","date":"2016-12-05T06:29:56.000Z","updated":"2019-05-16T08:47:44.379Z","comments":true,"path":"2016/12/05/Java里的hasMap和golang里的map/","link":"","permalink":"http://yoursite.com/2016/12/05/Java里的hasMap和golang里的map/","excerpt":"哈希表哈希表就是一种以键-值(key-value)存储数据的结构,我们只要输入待查找的键即Key,即可找到对应的值。使用哈希找查有两个步骤: 使用哈希函数将被找查的键转换为数组的索引.在理想的情况下,不同的键会被装换为不同的索引值,但是在有些情况下我们需要处理多个键被哈希到同一个索引值得情况。所以哈希查找的第二个步骤是处理冲突。 处理哈希碰撞冲突。一般处理哈希碰撞用拉链法和开放寻址法等方法。 开放地址法:当发生地址冲突时，按照某种方法继续探测哈希表中的其他存储单元，直到找到空位置为止。拉链法:当通过哈希函数把键转换为数组的索引时,如果索引重复,就在该位置用链表顺序 存储该键值对。 Java中的HashMap基本认识：基于Map接口,允许null键/值,非同步,不保证有序,也不保证顺序不随时间变化。HashMap中和Map一样，键值对都是保存在一个内部类中的,而在HashMap类中有一个很重要的字段，那就是Node[] table，即是一个哈希桶数组。Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)。 123456789static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; //用来定位数组索引位置 final K key; V value; Node&lt;K,V&gt; next; //链表的下一个node Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; ... &#125; /.../&#125;","text":"哈希表哈希表就是一种以键-值(key-value)存储数据的结构,我们只要输入待查找的键即Key,即可找到对应的值。使用哈希找查有两个步骤: 使用哈希函数将被找查的键转换为数组的索引.在理想的情况下,不同的键会被装换为不同的索引值,但是在有些情况下我们需要处理多个键被哈希到同一个索引值得情况。所以哈希查找的第二个步骤是处理冲突。 处理哈希碰撞冲突。一般处理哈希碰撞用拉链法和开放寻址法等方法。 开放地址法:当发生地址冲突时，按照某种方法继续探测哈希表中的其他存储单元，直到找到空位置为止。拉链法:当通过哈希函数把键转换为数组的索引时,如果索引重复,就在该位置用链表顺序 存储该键值对。 Java中的HashMap基本认识：基于Map接口,允许null键/值,非同步,不保证有序,也不保证顺序不随时间变化。HashMap中和Map一样，键值对都是保存在一个内部类中的,而在HashMap类中有一个很重要的字段，那就是Node[] table，即是一个哈希桶数组。Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)。 123456789static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; //用来定位数组索引位置 final K key; V value; Node&lt;K,V&gt; next; //链表的下一个node Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; ... &#125; /.../&#125; 还有两个重要参数: 容量(Capacity)：Capacity就是bucket的大小 负载因子(Load factor)：Load factor就是bucket填满程度的最大比例。如果对迭代性能要求很高的话不要把capacity设置过大,也不要吧load factor设置过小，当bucket的entries的数目大于capacity*load factor是就需要调整bucket的大小为当前的2倍。put()函数的基本思路: 对key的hashCode()做hash,然后计算对应的index 如果没有发生碰撞就直接放到桶里 如果发生碰撞就采用拉链法,以链表的形式存储在该桶里 如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD),就把链表转换为红黑树 如果节点存在,就替换成新的value 如果桶满了(超过load factor*current capacity),就要resize 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public V put(K key, V value)&#123; return putVal(hash(key),key,value,false,true);&#125;final V putVal(int hash,K key,V value,boolean onlyIfAbsent,boolean evict)&#123;Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // tab为空则创建 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 计算index，并对null做处理 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 节点存在 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 该链为树 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 该链为链表 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 写入 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 超过load factor*current capacity，resize if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; get()函数的基本思路 桶里的第一个节点就直接命中 如果桶里有冲突，就通过equal()来找查对应的entry，若为树时间复杂度为O(logN)，链表就是O(N) 123456789101112131415161718192021222324252627public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 直接命中 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 未命中 if ((e = first.next) != null) &#123; // 在树中get if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 在链表中get do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 注意:通过hash的方法，通过put和get存储和获取对象。存储对象时，我们将K/V传给put方法时,它调用hashCode计算hash从而得到bucket位置,进一步存储，HashMap会根据当前bucket的占用情况自动调整容量(超过Load Facotr则resize为原来的2倍)。获取对象时,我们将K传给get,它调用hashCode计算hash从而得到bucket位置,并进一步调用equals()方法确定键值对。如果发生碰撞的时候，HashMap通过链表将产生碰撞冲突的元素组织起来,在Java 8中,如果一个bucket中碰撞冲突的元素超过某个限制(默认是8,则使用红黑树来替换链表,从而提高速度 golang中的map基本认识:在go中一个map就是一个哈希表的引用,map类型可以写为map[K]V,对K的类型要求是必须支持==比较运算符。但是不建议使用浮点型作为Key。 1234567891011121314151617181920struct Hmap&#123;//map的关键数据 uint8 B; // 可以容纳2^B个项 uint16 bucketsize; // 每个桶的大小 .... byte *buckets; // 2^B个Buckets的数组 byte *oldbuckets; // 前一个buckets，只有当正在扩容时才不为空&#125;;//初始化的3种方式ages:=make(map[string]int)// mapping from strings to intsages:=map[string]int&#123;&#125;ages:=map[string]int&#123; \"alice\":0, \"charlie\":33,&#125;//取值ages[\"alice\"]=0//赋值ages[\"charlie\"]=34//删除delete(ages, \"alice\") // remove element ages[\"alice\"] 上面这些都是安全的，及时失败也会返回对应value类型的零值。但是有时候需要想知道对应的元素是否真的在map之中。推荐写法： 123//map的下标语法将产生两个值；第二个是一个布尔值 //用于报告元素是否真的存在。布尔变量一般命名为ok，特别适合马上用于if条件判断部分。if age, ok := ages[\"alice\"]; !ok &#123; /* ... */ &#125; 扩容在golang中主要采用增量扩容–扩容因子为6.5。这个主要是为了缩短map容器的响应时间，因为在map桶里面数据很多事,直接复制进行扩容就会很卡，导致较长一段时间无法响应请求。不过具体时间复杂度还是采用的均摊法。具体做法: 扩容会建立一个大小是原来2倍的空表。将旧的bucket搬到新表中(复制),但是并不会将旧的bucket从oldbucket中删除，而是加上一个已删除的标记。 由于整个过程是逐渐完成的,这样就会导致一部分数据还没有完全复制到新表，所以会对insert，remove，get等操作产生影响。并且只有当所有复制操作完成后才会释放oldbucket。 insert分析基本思路 根据key算出hash值，进而得出索引的位置 如果bucket的位置在old table中，就重新hash到新表中 查找对应的位置，如果在bucket中如果已经存在相应的key，就覆盖原来value，没有就插入 根据table中元素的个数，判断是否扩容 如果对应的bucket已经full，重新申请新的bucket作为overbucket(溢出桶链表)。 将key/value pair插入到bucket中。 get查找过程 根据key算出hash值，进而得出索引的位置 如果存在old table, 首先在old table中查找，如果找到的bucket已经扩容，转到步骤3。 反之，返回其对应的value。 在new table中查找对应的value。 1234567891011121314do &#123; //对每个bucket //依次比较桶内的每一项存放的高位hash与所求的hash值高位是否相等 for(i = 0, k = b-&gt;data, v = k + h-&gt;keysize * BUCKETSIZE; i &lt; BUCKETSIZE; i++, k += h-&gt;keysize, v += h-&gt;valuesize) &#123; if(b-&gt;tophash[i] == top) &#123; k2 = IK(h, k); t-&gt;key-&gt;alg-&gt;equal(&amp;eq, t-&gt;key-&gt;size, key, k2); if(eq) &#123; //相等的情况下再去做key比较... *keyp = k2; return IV(h, v); &#125; &#125; &#125; b = b-&gt;overflow; //b设置为它的下一下溢出链&#125; while(b != nil); 这里一个细节需要注意一下。不认真看可能会以为低位用于定位bucket在数组的index，那么高位就是用于key/valule在bucket内部的offset。事实上高8位不是用作offset的，而是用于加快key的比较的。 总结在扩容过程中，oldbucket是被冻结的，查找时会在oldbucket中查找，但不会在oldbucket中插入数据。如果在oldbucket是找到了相应的key，做法是将它迁移到新bucket后加入扩容标记。然后就是只要在某个bucket中找到第一个空位，就会将key/value插入到这个位置。也就是位置位于bucket前面的会覆盖后面的(类似于存储系统设计中做删除时的常用的技巧之一，直接用新数据追加方式写，新版本数据覆盖老版本数据)。找到了相同的key或者找到第一个空位就可以结束遍历了。不过这也意味着做删除时必须完全的遍历bucket所有溢出链，将所有的相同key数据都删除。所以目前map的设计是为插入而优化的，删除效率会比插入低一些。 参考:Java 8系列之重新认识HashMapJava HashMap工作原理及实现","categories":[{"name":"Java和golang","slug":"Java和golang","permalink":"http://yoursite.com/categories/Java和golang/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"}]},{"title":"golang的切片和Java的动态数组","slug":"golang的切片和Java的动态数组","date":"2016-11-29T09:44:44.000Z","updated":"2019-05-16T08:42:26.029Z","comments":true,"path":"2016/11/29/golang的切片和Java的动态数组/","link":"","permalink":"http://yoursite.com/2016/11/29/golang的切片和Java的动态数组/","excerpt":"Java里的动态数组—ArrayListArrayList是实现List接口的动态数组，每个ArrayList实例都有一个容量，该容量是指用来存储列表元素的数组的大小。随着向ArrayList中不断添加元素，容量会自动增长，自动增长会带来数据向新数组的重新拷贝。同时需要注意的是这个实现不是同步的。如果多个线程同时访问一个ArrayList实例，而其中至少一个线程从结构上修改了列表，那么它必须保持外部同步。(结构上的修改是指任何添加或删除一个或多个元素的的操作，或者显示调整底层数组的大小；仅仅设置元素的值不是结构上的修改)","text":"Java里的动态数组—ArrayListArrayList是实现List接口的动态数组，每个ArrayList实例都有一个容量，该容量是指用来存储列表元素的数组的大小。随着向ArrayList中不断添加元素，容量会自动增长，自动增长会带来数据向新数组的重新拷贝。同时需要注意的是这个实现不是同步的。如果多个线程同时访问一个ArrayList实例，而其中至少一个线程从结构上修改了列表，那么它必须保持外部同步。(结构上的修改是指任何添加或删除一个或多个元素的的操作，或者显示调整底层数组的大小；仅仅设置元素的值不是结构上的修改) Java里面的初始化和实现123456789101112131415161718192021222324252627282930313233343536 public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; //设置arrayList默认容量 private static final int DEFAULT_CAPACITY = 10; //空数组，当调用无参数构造函数的时候默认给个空数组 private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; //这才是真正保存数据的数组 private transient Object[] elementData; //arrayList的实际元素数量 private int size; //构造方法传入默认的capacity 设置默认数组大小 public ArrayList(int initialCapacity) &#123; super(); if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); this.elementData = new Object[initialCapacity]; &#125; //无参数构造方法默认为空数组 public ArrayList() &#123; super(); this.elementData = EMPTY_ELEMENTDATA; &#125; //构造方法传入一个Collection， 则将Collection里面的值copy到arrayList public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); size = elementData.length; if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125;&#125; 从上面的源码可以看出来，ArrayList的本质就是数组的，其中的add,get,set,remove等操作都是对数组的操作，所以ArrayList的特性基本都是源于数组:有序、元素可以重复、插入慢、获取快等特性。 ArrayList里面的将数组动态扩容实现add和remove123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 //在末尾增加元素，虽然有时需要扩容但是时间复杂度为O(1)public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; &#125; //在数组中间增加元素，因为需要移动后面的元素，所以时间复杂度为O(n) public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; &#125; private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity); &#125; private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; //超出了数组可容纳的长度，需要进行动态扩展 if (minCapacity - elementData.length &gt; 0) grow(minCapacity); &#125; //这才是动态扩展的核心 private void grow(int minCapacity) &#123; int oldCapacity = elementData.length; //设置新数组的容量扩展为原来数组的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //再判断一下新数组的容量够不够，够了就直接使用这个长度创建新数组， 不够就将数组长度设置为需要的长度 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //判断有没超过最大限制 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); //将原来数组的值copy新数组中去 elementData = Arrays.copyOf(elementData, newCapacity); &#125; private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; 从上面的ArrayList的源码就可以知道,整个ArrayList的动态实现就是在增加数据的时候判断数组的容量是否足够,不够就重新生成一个1.5倍的数组,然后进行复制。这就是整个ArrayList的核心。 golang里面的动态数组—sliceGo中的数组定义在Go中的数组和Java有点不一样。在golang中数组是内置类型,初始化后长度是固定的，没有办法修改其长度,数组的长度也是其类型的一部分。数组是值类型,通过从0开始的下标索引访问元素值。值得注意的是如果GO中的数组作为函数的参数，那么实际传递的参数是一份数组的拷贝,而不是数组的指针。 123var b [5]int //没有初始值，会自动的给出默认值&#123;0,0,0,0,0&#125;a:=[5]int&#123;1,2,3,4,5&#125;b:=[...]int&#123;1,2,3,4,5&#125; slice数组的长度是不可改变的,在很多场景都不是很适用，但是slice不一样。slice是golang的内置类型。在slice中有两个概念,和数组一样，有两个内置的属性：一个是len长度，一个是cap容量。slice是应用类型,因此当传递切片将和应用同一指针，修改值会影响其他的对象。 12//一般建议的初始化是用make()来初始化var a []int 上面就可以表示一个slice,和声明数组差不多。只是少了一个长度。slice也可以从一个数组或者已经存在的slice中再次声明。slice通过a[i:j]来获取,其中i是数组的开始位置,j是结束位置(不包含),长度为j-i 1234567891011121314// 声明一个含有10个元素元素类型为byte的数组var arr = [10]byte &#123;'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'&#125;// 声明两个含有byte的slicevar a, b ,c ,d[]byte// a指向数组的第3个元素开始，并到第五个元素结束，现在a含有的元素: arr[2]、arr[3]和ar[4]a = arr[2:5]// b是数组arr的另一个slice, b的元素是：arr[3]和arr[4]b = arr[3:5]//c是数组arr的另一个slice,c的元素师:arr[0],arr[1],arr[2]c = arr [:3]//slice的默认开始位置是0，arr[:n]等价于arr[0:n]//slice的第二个序列默认是数组的长度，ar[n:]等价于ar[n:len(ar)]//如果从一个数组里面直接获取slice，可以这样ar[:],因为默认第一个序列是0，第二个是数组的长度，即等价于ar[0:len(ar)] 基本结构如下：slice是引用类型,所以修改a中元素中的值，那么b中的值也会改变。对于slice有几个有用的内置函数： len()获取slice的长度 cap()获取slice的最大容量 append() 向slice中追加一个或者多个元素，然后返回一个和slice一样类型的slice copy() 从源slice的src中复制元素到目标dst，并且返回复制的元素的个数slice一般都是通过make()进行实例化操作,在进行扩容是用append(),如果直接加入的个数打入slice的初始容量会报错。 123456//基本用法slice := append([]int&#123;1,2,3&#125;,4,5,6)//合并两个sliceslice := append([]int&#123;1,2,3&#125;,[]int&#123;4,5,6&#125;...)//将字符串当作[]byte类型作为第二个参数传入bytes := append([]byte(\"hello\"),\"world\"...) 需要注意的是append()函数会改变slice的引用。cap不足时会按照cap的两倍进行扩容。 有意思的算法—扩容首先有一个问题:在ArrayList中扩容是通过复制整个数组完成,每次当数组的容量满了，就会重新建一个长度是上次两倍的数组，然后进行复制操作，然后释放掉原来的数组。时间复杂度可以简单的看作使用for循环的嵌套，在复制数组的时候相当于用for循环来遍历了一遍数组。所以复制的时间复杂度应该是O(N)的。但是整个ArrayList在末尾插入的时候表现是很快的。这里就有一个均摊的思想。 首先并不是每个元素的插入都会触发复制扩容这个操作。只有才数组长度不够的情况下，才会产生。然后均摊下来就是o(1)了。所以在某些情况下AarryList的性能会出现波动也是这个原因。","categories":[{"name":"Java和golang","slug":"Java和golang","permalink":"http://yoursite.com/categories/Java和golang/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"}]},{"title":"IP初识","slug":"IP初识","date":"2016-11-28T06:18:00.000Z","updated":"2019-05-16T08:47:48.283Z","comments":true,"path":"2016/11/28/IP初识/","link":"","permalink":"http://yoursite.com/2016/11/28/IP初识/","excerpt":"基本认识&emsp;最近一次接触ip是在我读《TCP/IP详解》时读到了，其实我感觉这些基础对理解整个互联网的结构都有一些很好的认识，在TCP/IP的协议簇中，首先简单的说一下在TCP中分层： 数据链路层:一般都是物理设备驱动程序和接口 网络层:处理分组在网络中的活动，如分组选路。TCP/IP中,IP协议,ICMP协议,IGMP协议 运输层:主要为应用程序提供端到端的通信，主要包括两种协议:TCP(高可靠的)、UDP(不可靠的，效率高的) 应用层:负责处理特定的应用程序的细节上图是我认为对TCP/IP分层的理解很好的一张图TCP/IP分层和传统的OSI分层不一样。OSI的7层是分的更加详细。对于TCP/IP的协议簇重点关注的还是网络层，运输层。","text":"基本认识&emsp;最近一次接触ip是在我读《TCP/IP详解》时读到了，其实我感觉这些基础对理解整个互联网的结构都有一些很好的认识，在TCP/IP的协议簇中，首先简单的说一下在TCP中分层： 数据链路层:一般都是物理设备驱动程序和接口 网络层:处理分组在网络中的活动，如分组选路。TCP/IP中,IP协议,ICMP协议,IGMP协议 运输层:主要为应用程序提供端到端的通信，主要包括两种协议:TCP(高可靠的)、UDP(不可靠的，效率高的) 应用层:负责处理特定的应用程序的细节上图是我认为对TCP/IP分层的理解很好的一张图TCP/IP分层和传统的OSI分层不一样。OSI的7层是分的更加详细。对于TCP/IP的协议簇重点关注的还是网络层，运输层。 在TCP/IP中有一个分层的概念值得注意: 应用层关心的是应用程序的细节，而不是数据在网络中的传输活动。下三层对应用程序一无所知，但它们要处理所有的通信细节.IP协议是一种不可靠的网络层服务,它只是尽可能的快地把分组从源节点送到目的节点,并不提供任何可靠性的保证,但是IP得可靠服务可以由上层协议(TCP)来提供。 IP地址的分类 &emsp;互联网上每个接口必须有一个唯一32位的Internet地址(IP地址),基本分类如下：IP地址是具有一定基本结构，一共有5类地址,每一类都包括:标志位、网络号、主机号。5类地址分为三种:单播地址(目的为单个主机,有:A、B、C)，广播地址(目的端为给定网络上的所有主机:D),多播地址(目的端为同一组内的所有主机:E)。 IP路由选择&emsp;在一般的通信中，IP可以从TCP、UDP、ICMP、接受数据报(即本地生成的数据报)并进行发送，或者从一个网络接口接受数据报并进行转发。IP层在内存中有一个路由表。当收到一份数据报并进行发送时，它都要对该表搜索一次。当数据报来自某个网络接口时，IP首先检查目的IP地址是否为本机的IP地址之一或者IP广播地址。如果确实是这样，数据报就被送到处理。如果数据报的目的不是这些地址，那么如果IP层被设置为路由器的功能，那么就对数据报进行转发，否则数据报就被丢弃。并且IP数据包的TTL(生命周期)为0，则该IP数据包就也会被抛弃。路由表中一般包含：目的IP地址，数据报传输的网络接口，下一跳的IP地址。&emsp;IP路由选择是逐跳进行的。IP不知道到达任何目地的完整路径(除了与主机 直接相连的目的地)。所有的IP路由选择只为数据报传输提供下一站路由器的IP地址。它假定下一站路由器比发送数据报的主机更接近目的路由。如果IP数据报不能送达且来自本机那么一般会想生成数据报的应用程序返回一个“主机不可达”或“网络不可达”的错误。基本过程: 如果ip数据包的TTL为0,则该IP数据报直接被丢弃 搜索路由表，优先搜索匹配主机，如果能找到和IP地址完全一致的目标主机,则将该包发向目标主机 搜索路由表，如果匹配主机失败，则匹配同子网的路由器，如果找到，则将该包发向路由器 搜索路由表，如果匹配同子网路由器失败，内匹配同网号路由器，如果找到，则将该包发向路由器 搜索路由表，如果以上都失败了，就搜索默认路由 如果都失败了，就直接丢弃子网寻址&emsp;现在的所有主机都要求支持子网编址。不是把IP地址看成由单纯的一个网络号和一个主机号组成，而是把主机号在分成一个子网号和一个主机号。这样做的原因就是应为A类和B类地址为主机号分配了太多的空间，可分别容纳的主机数为16777214和65534个主机,但是事实上,在一个网络中一般安排不了这么多的主机。下图为B类子网划分的例子:上面是一个B类网络地址(140.252),在剩下的16位中，8为用于子网号,8为用于主机号,这样就允许254个子网,每个子网就可以有254台主机。 IP的子网掩码&emsp;由于除了IP地址外，主机还需要知道有那几位是子网号,那几位是主机号,这两个信息都是通过子网掩码来获得 ps:判断一个IP地址所属的类别，一般看IP地址的开头就行，不看子网掩码。一般0~127是A类,128~191是B类,192~223是C类，224~239是D类。 ARP协议—地址解析协议&emsp;首先在以太网协议中的规定，同一局域网的一台主机要和另一台主机进行通信，必须知道目标主机的MAC地址。但是在TCP/IP协议中，网络层和传输层都只关心目标主机的IP地址.所以这个ARP协议就是IP和MAC的一种映射。具体过程:当A:192.168.10.11向B：192.168.10.19发送数据时，主机A首先会在自己的ARP缓存表(IP-MAC地址的对应表)中寻找是否有目标的MAC，如果不存在，那么主机就向同一网段的网络发送一个ARP协议的广播包(谁知道192.168.10.19的MAC地址)，网络上其他主机并不会响应ARP的广播，只有主机B接受大这个广播才会向主机A做出回应。主机A就知道主机B的MAC地址，它就可以向主机B发送信息。同时它还更新自己的ARP缓存表，下次再向主机B发送信息时，直接从ARP缓存表里查找就可。同时ARP缓存表采用老化机制，在一段时间内如果表中的某一行没有使用，就会被删除，这样可以大大减少ARP缓存表的长度，加快查询速度。","categories":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://yoursite.com/categories/TCP-IP/"}],"tags":[{"name":"ip","slug":"ip","permalink":"http://yoursite.com/tags/ip/"}]},{"title":"第一篇博客","slug":"第一篇博客","date":"2016-11-25T08:42:04.000Z","updated":"2019-04-24T06:43:52.000Z","comments":true,"path":"2016/11/25/第一篇博客/","link":"","permalink":"http://yoursite.com/2016/11/25/第一篇博客/","excerpt":"","text":"开始写了有点小激动&emsp;&emsp;第一篇博客，其实以前也写过一些博文，但是都是不成体系的，一直都想写，但是总被一些事情给牵住了，终于可以开始第一篇博文的书写。这个博客主要记录我从大四实习开始的路程，不知道以后这个博客可以坚持多长时间，但是希望越久越好。我现在主要方向还是Java和golang的后端开发。因为两个的基础都不是很好。积累基础是一个很缓慢的过程，所以只能慢慢的往上爬。不能急。我会在博客中更新我最近学习的东西，和在工作中的坑。希望自己的技术能越来越来。说不定，以后就给自己的博客一个独立的域名，只是现在，刚开始。不急。","categories":[{"name":"essay","slug":"essay","permalink":"http://yoursite.com/categories/essay/"}],"tags":[{"name":"start","slug":"start","permalink":"http://yoursite.com/tags/start/"}]}]}